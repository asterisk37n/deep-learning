{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8449,
     "status": "ok",
     "timestamp": 1528290515977,
     "user": {
      "displayName": "Utkarsh Desai",
      "photoUrl": "//lh5.googleusercontent.com/-GB3uo08xXVQ/AAAAAAAAAAI/AAAAAAAAAOU/jAWv2N45tis/s50-c-k-no/photo.jpg",
      "userId": "110459383793799626724"
     },
     "user_tz": -330
    },
    "id": "_vA8knol6rGi",
    "outputId": "4d58ad61-13a9-4767-8651-19e495ecb03b"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Reshape, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, Conv2D, Conv2DTranspose\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MZRiRjRj6xO4"
   },
   "outputs": [],
   "source": [
    "def get_generator():\n",
    "    z = Input(shape=(100,)) # noize\n",
    "    c = Input(shape=(10,)) # condition. In this case, c is supposed to be a one-hot vector of CIFAR-10\n",
    "    merged_input = Concatenate()([z, c])\n",
    "\n",
    "    hid = Dense(128 * 8 * 8, activation='relu')(merged_input)    \n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.2)(hid)\n",
    "    hid = Reshape((8, 8, 128))(hid)\n",
    "    \n",
    "    hid = Conv2D(128, kernel_size=4, strides=1,padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)    \n",
    "    hid = LeakyReLU(alpha=0.2)(hid)\n",
    "\n",
    "    hid = Conv2DTranspose(128, 4, strides=2, padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.2)(hid)\n",
    "\n",
    "    hid = Conv2D(128, kernel_size=5, strides=1,padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)    \n",
    "    hid = LeakyReLU(alpha=0.2)(hid)\n",
    "\n",
    "    hid = Conv2DTranspose(128, 4, strides=2, padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.2)(hid)\n",
    "\n",
    "    hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.2)(hid)\n",
    "\n",
    "    hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.2)(hid)\n",
    "\n",
    "    hid = Conv2D(3, kernel_size=5, strides=1, padding=\"same\")(hid) # 32, 32, 3\n",
    "    out = Activation(\"tanh\")(hid)\n",
    "\n",
    "\n",
    "    model = Model(inputs=[z, c], outputs=out)\n",
    "    model.summary()\n",
    "\n",
    "    return model, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4yFseSJQ62d2"
   },
   "outputs": [],
   "source": [
    "def get_discriminator():\n",
    "    x = Input(shape=(32, 32, 3))\n",
    "    c = Input(shape=(10,))\n",
    "    hid = Conv2D(128, kernel_size=3, strides=1, padding='same')(x)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.2)(hid)\n",
    "\n",
    "    hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.2)(hid)\n",
    "\n",
    "    hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.2)(hid)\n",
    "\n",
    "    hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.2)(hid)\n",
    "\n",
    "    hid = Flatten()(hid)\n",
    "\n",
    "    c = Input(shape=(10,))\n",
    "    merged_layer = Concatenate()([hid, c])\n",
    "    hid = Dense(512, activation='relu')(merged_layer)\n",
    "    hid = LeakyReLU(alpha=0.2)(hid)\n",
    "    hid = Dropout(0.4)(hid)\n",
    "    out = Dense(1, activation='sigmoid')(hid)\n",
    "\n",
    "    model = Model(inputs=[x, c], outputs=out)\n",
    "    model.summary()\n",
    "\n",
    "    return model, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uFSdLdMv67Oq"
   },
   "outputs": [],
   "source": [
    "# --------\n",
    "# Prepare some utilities\n",
    "# --------\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def one_hot_encode(y):\n",
    "    z = np.zeros((len(y), 10))\n",
    "    idx = np.arange(len(y))\n",
    "    z[idx, y] = 1\n",
    "    return z\n",
    "\n",
    "def generate_noise(n_samples, noise_dim):\n",
    "    X = np.random.normal(0, 1, size=(n_samples, noise_dim))\n",
    "    return X\n",
    "\n",
    "def generate_random_labels(n):\n",
    "    y = np.random.choice(10, n)\n",
    "    y = one_hot_encode(y)\n",
    "    return y\n",
    "\n",
    "tags = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "  \n",
    "def show_samples():\n",
    "    fig, axs = plt.subplots(5, 6, figsize=(10,6))\n",
    "    plt.subplots_adjust(hspace=0.3, wspace=0.1)\n",
    "    #fig, axs = plt.subplots(5, 6)\n",
    "    #fig.tight_layout()\n",
    "    for classlabel in range(10):\n",
    "        row = int(classlabel / 2)\n",
    "        coloffset = (classlabel % 2) * 3\n",
    "        lbls = one_hot_encode([classlabel] * 3)\n",
    "        noise = generate_noise(3, 100)\n",
    "        gen_imgs = generator.predict([noise, lbls])\n",
    "\n",
    "        for i in range(3):\n",
    "            # Dont scale the images back, let keras handle it\n",
    "            img = image.array_to_img(gen_imgs[i], scale=True)\n",
    "            axs[row,i+coloffset].imshow(img)\n",
    "            axs[row,i+coloffset].axis('off')\n",
    "            if i ==1:\n",
    "                axs[row,i+coloffset].set_title(tags[classlabel])\n",
    "    plt.show()\n",
    "    plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4753,
     "status": "ok",
     "timestamp": 1528290526882,
     "user": {
      "displayName": "Utkarsh Desai",
      "photoUrl": "//lh5.googleusercontent.com/-GB3uo08xXVQ/AAAAAAAAAAI/AAAAAAAAAOU/jAWv2N45tis/s50-c-k-no/photo.jpg",
      "userId": "110459383793799626724"
     },
     "user_tz": -330
    },
    "id": "Iha5HiXj7FRg",
    "outputId": "4c0f2698-b792-4dcb-bb17-8c004f545b97"
   },
   "outputs": [],
   "source": [
    "# -------\n",
    "# Compile discriminator\n",
    "# -------\n",
    "discriminator, disc_out = get_discriminator()\n",
    "discriminator.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# --------\n",
    "# Compile combined model with untrainable discriminator\n",
    "# --------\n",
    "discriminator.trainable = False\n",
    "\n",
    "combined_input = Input(shape=(100,))\n",
    "combined_condition = Input(shape=(10,))\n",
    "generator, gen_out = get_generator()\n",
    "x = generator([combined_input, combined_condition])\n",
    "combined_out = discriminator([x, combined_condition])\n",
    "combined = Model(inputs=[combined_input, combined_condition], output=combined_out)\n",
    "combined.summary()\n",
    "\n",
    "combined.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55917,
     "status": "ok",
     "timestamp": 1528290582813,
     "user": {
      "displayName": "Utkarsh Desai",
      "photoUrl": "//lh5.googleusercontent.com/-GB3uo08xXVQ/AAAAAAAAAAI/AAAAAAAAAOU/jAWv2N45tis/s50-c-k-no/photo.jpg",
      "userId": "110459383793799626724"
     },
     "user_tz": -330
    },
    "id": "x_C473Ji7OtQ",
    "outputId": "be4916aa-ed6c-485e-9ff4-d4dd1cfebe37"
   },
   "outputs": [],
   "source": [
    "# --------\n",
    "# Prepare data\n",
    "# -------\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# # Get training images\n",
    "(X_train, c_train), (X_test, c_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize data\n",
    "X_train = (X_train - 127.5) / 127.5\n",
    "X_test = (X_test - 127.5) / 127.5\n",
    "# 1hot encode labels\n",
    "c_train = one_hot_encode(c_train[:,0])\n",
    "c_test = one_hot_encode(c_test[:,0])\n",
    "\n",
    "print (\"Training shape: {}\".format(X_train.shape))\n",
    "print (\"Test     shape: {}\".format(X_test.shape))\n",
    " \n",
    "num_train_batches = X_train.shape[0] // BATCH_SIZE\n",
    "num_test_batches = X_test.shape[0] // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "JST = datetime.timezone(datetime.timedelta(hours=+9), 'JST')\n",
    "start_time = datetime.datetime.now(JST)\n",
    "print(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1961
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1097611,
     "status": "ok",
     "timestamp": 1528295720240,
     "user": {
      "displayName": "Utkarsh Desai",
      "photoUrl": "//lh5.googleusercontent.com/-GB3uo08xXVQ/AAAAAAAAAAI/AAAAAAAAAOU/jAWv2N45tis/s50-c-k-no/photo.jpg",
      "userId": "110459383793799626724"
     },
     "user_tz": -330
    },
    "id": "jUgkE7bW7ZNK",
    "outputId": "b8e87309-5418-42db-acb5-3ce3ea4e8508",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --------\n",
    "# Train and test\n",
    "# --------\n",
    "\n",
    "EPOCHS = 100\n",
    "d_losses = []\n",
    "d_accs   = []\n",
    "g_losses = []\n",
    "\n",
    "# Prepare labels as ground truth of discrimination output\n",
    "true_labels = np.ones((BATCH_SIZE, 1))\n",
    "fake_labels = np.zeros((BATCH_SIZE, 1))\n",
    "\n",
    "print(\"Training started.\")\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # shuffle all data on starting epoch\n",
    "    s = np.arange(X_train.shape[0])\n",
    "    X_train = X_train[s]\n",
    "    c_train = c_train[s]\n",
    "    \n",
    "    # Train\n",
    "    for batch_idx_train in range(num_train_batches):\n",
    "        # Get the set of images and labels (here used as conditions) from CIFAR-10 dataset\n",
    "        true_images      = X_train[batch_idx_train * BATCH_SIZE : (batch_idx_train + 1) * BATCH_SIZE]\n",
    "        true_conditions  = c_train[batch_idx_train * BATCH_SIZE : (batch_idx_train + 1) * BATCH_SIZE]\n",
    "\n",
    "        noise_data        = generate_noise(BATCH_SIZE, 100)\n",
    "        random_conditions = generate_random_labels(BATCH_SIZE)\n",
    "        generated_images  = generator.predict([noise_data, random_conditions])\n",
    "\n",
    "        # Train discriminator on real data whose label is one\n",
    "        d_loss_true_train = discriminator.train_on_batch([true_images, true_conditions], true_labels)\n",
    "\n",
    "        # Train discriminator on generated data whose label is zero\n",
    "        d_loss_fake       = discriminator.train_on_batch([generated_images, random_conditions], fake_labels)\n",
    "\n",
    "        # Train generator. Generator tries to cheat discriminator so a label need set to be one\n",
    "        # Learning goes on so that a network produces labels\n",
    "        g_loss_train      = combined.train_on_batch([noise_data, random_conditions], true_labels)\n",
    "    \n",
    "    # Test at the end of every epoch\n",
    "    # store discriminator's and generator's loss at every batch and then calculate average at the end of epoch \n",
    "    d_losses_in_epoch = []\n",
    "    d_accs_in_epoch = []\n",
    "    g_losses_in_epoch = []\n",
    "    for batch_idx_test in range(num_test_batches):\n",
    "        test_images     = X_test[batch_idx_test * BATCH_SIZE : (batch_idx_test + 1) * BATCH_SIZE]\n",
    "        test_conditions = c_test[batch_idx_test * BATCH_SIZE : (batch_idx_test + 1) * BATCH_SIZE]\n",
    "\n",
    "        d_loss_test_batch = discriminator.test_on_batch([test_images, test_conditions], true_labels)\n",
    "        g_loss_test_batch = combined.test_on_batch([noise_data, random_conditions], true_labels)\n",
    "\n",
    "        d_losses_in_epoch.append(d_loss_test_batch[0])\n",
    "        d_accs_in_epoch.append(d_loss_test_batch[1])\n",
    "        g_losses_in_epoch.append(g_loss_test_batch)\n",
    "        \n",
    "    d_loss = np.average(d_losses_in_epoch)\n",
    "    d_acc  = np.average(d_accs_in_epoch)\n",
    "    g_loss = np.average(g_losses_in_epoch)\n",
    "\n",
    "    d_losses.append(d_loss)\n",
    "    d_accs.append(d_acc)\n",
    "    g_losses.append(g_loss)\n",
    "    print('Epoch: {}; Generator Loss: {:.4f}; Discriminator Loss: {:.4f}, Acc: {:.4f}'.format(epoch + 1, g_loss, d_loss, d_acc))\n",
    "    show_samples()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2785
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6700,
     "status": "ok",
     "timestamp": 1528292805833,
     "user": {
      "displayName": "Utkarsh Desai",
      "photoUrl": "//lh5.googleusercontent.com/-GB3uo08xXVQ/AAAAAAAAAAI/AAAAAAAAAOU/jAWv2N45tis/s50-c-k-no/photo.jpg",
      "userId": "110459383793799626724"
     },
     "user_tz": -330
    },
    "id": "uK19Aj0bir2R",
    "outputId": "a2ae81fe-4f5c-4689-8b36-0163c70b671a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for classlabel in range(10):\n",
    "    lbls = one_hot_encode([classlabel] * 9)\n",
    "    noise = generate_noise(9, 100)\n",
    "    gen_imgs = generator.predict([noise, lbls])\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3)\n",
    "    plt.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "    count = 0\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            # Dont scale the images back, let keras handle it\n",
    "            img = image.array_to_img(gen_imgs[count], scale=True)\n",
    "            axs[i,j].imshow(img)\n",
    "            axs[i,j].axis('off')\n",
    "            plt.suptitle('Label: ' + str(classlabel))\n",
    "            count += 1\n",
    "    plt.show()\n",
    "    plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------\n",
    "# Plot generator and discriminator accuracy and loss all\n",
    "# --------\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "x = [i + 1 for i in range(len(d_losses))]\n",
    "plt.plot(x, d_losses, label=\"d_loss\")\n",
    "plt.plot(x, d_accs,   label=\"d_acc\")\n",
    "plt.plot(x, g_losses, label=\"g_loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('a.u.')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------\n",
    "# Plot generator and discriminator accuracy and loss by 1000 epoochs\n",
    "# --------\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "x = [i + 1 for i in range(len(d_losses))]\n",
    "plt.plot(x, d_losses, label=\"d_loss\")\n",
    "plt.plot(x, d_accs,   label=\"d_acc\")\n",
    "plt.plot(x, g_losses, label=\"g_loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('a.u.')\n",
    "plt.xlim((0,80))\n",
    "plt.ylim((0, 3))\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(ticks = [i for i in range(0, 80, 5)])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished_time = datetime.datetime.now(JST)\n",
    "print(finished_time)\n",
    "print('One epoch took {:.0f} seconds'.format((finished_time - start_time).total_seconds() // 351))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "FinalConditionalGAN.ipynb",
   "provenance": [
    {
     "file_id": "1XOimt_9w-jG29p--GFhwnTFPtcipDPDU",
     "timestamp": 1528364443663
    },
    {
     "file_id": "10Xz5Ln9_hRhTwCxvw2WF9GA4dIroWaJx",
     "timestamp": 1526016070352
    },
    {
     "file_id": "1UgFD1dV4_jc50xPcsGdt5pDeBPAXACcl",
     "timestamp": 1525522264892
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
