{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pix2Pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from data_loader import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import skimage\n",
    "import imageio\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    \"\"\"\n",
    "    supposed\n",
    "    ./datasets/(dataset_name)/train/source/0.jpg\n",
    "    ./datasets/(dataset_name)/train/target/0.jpg\n",
    "    ./datasets/(dataset_name)/test/source/0.jpg\n",
    "    ./datasets/(dataset_name)/test/target/0.jpg\n",
    "    ...\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_name, img_res=(128, 128)):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.img_res = img_res\n",
    "\n",
    "    def load_data(self, batch_size=1, is_testing=False):\n",
    "        data_type = \"train\" if not is_testing else \"test\"\n",
    "        img_source_dir = './datasets/%s/%s/source/*' % (self.dataset_name, data_type)\n",
    "        img_source_paths = glob.glob(img_source_dir)\n",
    "        img_source_batch = np.random.choice(img_source_paths, size=batch_size)\n",
    "\n",
    "        imgs_source, imgs_target = [], []\n",
    "        for img_source_path in img_source_batch:\n",
    "            img_source = self.imread(img_source_path)\n",
    "            img_target = self.imread(img_source_path.replace('source', 'target'))\n",
    "\n",
    "            img_source = skimage.transform.resize(img_source, self.img_res)\n",
    "            img_target = skimage.transform.resize(img_target, self.img_res)\n",
    "\n",
    "            if not is_testing and np.random.random() > 0.5:\n",
    "                img_source = np.fliplr(img_source)\n",
    "                img_target = np.fliplr(img_target)\n",
    "\n",
    "            imgs_source.append(img_source)\n",
    "            imgs_target.append(img_target)\n",
    "\n",
    "        imgs_source = np.array(imgs_source) / 255\n",
    "        imgs_target = np.array(imgs_target) / 255\n",
    "\n",
    "        return imgs_source, imgs_target\n",
    "\n",
    "    def load_batch(self, batch_size=1, is_testing=False):\n",
    "        data_type = \"train\" if not is_testing else \"test\"\n",
    "        img_source_dir = './datasets/%s/%s/source/*' % (self.dataset_name, data_type)\n",
    "        img_source_paths = glob.glob(img_source_dir)[::6]\n",
    "\n",
    "        self.n_batches = len(img_source_paths) // batch_size\n",
    "\n",
    "        for i in range(self.n_batches-1):\n",
    "            img_source_batch = img_source_paths[i*batch_size:(i+1)*batch_size]\n",
    "            imgs_source, imgs_target = [], []\n",
    "            for img_source_path in img_source_batch:\n",
    "                img_source = self.imread(img_source_path)\n",
    "                img_target = self.imread(img_source_path.replace('source', 'target'))\n",
    "\n",
    "                img_source = skimage.transform.resize(img_source, self.img_res)\n",
    "                img_target = skimage.transform.resize(img_target, self.img_res)\n",
    "\n",
    "                if not is_testing and np.random.random() > 0.5:\n",
    "                        img_source = np.fliplr(img_source)\n",
    "                        img_target = np.fliplr(img_target)\n",
    "\n",
    "                imgs_source.append(img_source)\n",
    "                imgs_target.append(img_target)\n",
    "\n",
    "            imgs_source = np.array(imgs_source) / 255\n",
    "            imgs_target = np.array(imgs_target) / 255\n",
    "\n",
    "            yield imgs_source, imgs_target\n",
    "\n",
    "    def imread(self, path):\n",
    "        return imageio.imread(path, as_gray=False, pilmode='RGB').astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2Pix():\n",
    "    def __init__(self, dataset_name='facades'):\n",
    "        # Input shape\n",
    "        self.img_rows = 256\n",
    "        self.img_cols = 256\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = dataset_name\n",
    "        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
    "                                      img_res=(self.img_rows, self.img_cols))\n",
    "\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = self.img_rows // 2**4\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(\n",
    "            loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        img_source = Input(shape=self.img_shape)\n",
    "        img_fake = self.generator(img_source)\n",
    "        self.discriminator.trainable = False\n",
    "        validity = self.discriminator([img_fake, img_source])\n",
    "\n",
    "        self.combined = Model(inputs=img_source, outputs=[validity, img_fake])\n",
    "        self.combined.compile(\n",
    "            loss=['mse', 'mae'],\n",
    "            loss_weights=[1, 100],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self, gf=64):\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "        self.gf = gf\n",
    "\n",
    "        def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = BatchNormalization(momentum=0.8)(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u\n",
    "\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        d1 = conv2d(d0, self.gf, bn=False)\n",
    "        d2 = conv2d(d1, self.gf*2)\n",
    "        d3 = conv2d(d2, self.gf*4)\n",
    "        d4 = conv2d(d3, self.gf*8)\n",
    "        d5 = conv2d(d4, self.gf*8)\n",
    "        d6 = conv2d(d5, self.gf*8)\n",
    "        d7 = conv2d(d6, self.gf*8)\n",
    "\n",
    "        u1 = deconv2d(d7, d6, self.gf*8)\n",
    "        u2 = deconv2d(u1, d5, self.gf*8)\n",
    "        u3 = deconv2d(u2, d4, self.gf*8)\n",
    "        u4 = deconv2d(u3, d3, self.gf*4)\n",
    "        u5 = deconv2d(u4, d2, self.gf*2)\n",
    "        u6 = deconv2d(u5, d1, self.gf)\n",
    "\n",
    "        u7 = UpSampling2D(size=2)(u6)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n",
    "\n",
    "        return Model(d0, output_img)\n",
    "\n",
    "    def build_discriminator(self, df=64):\n",
    "        self.df = df\n",
    "\n",
    "        def d_layer(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # Concatenate image and conditioning image by channels to produce input\n",
    "        combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
    "\n",
    "        d1 = d_layer(combined_imgs, self.df, bn=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model([img_A, img_B], validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=1):\n",
    "        self.epochs = epochs\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "\n",
    "        self.scores = [] # d_real_loss, d_real_acc, d_fake_loss, d_fake_acc, g_loss, g_acc\n",
    "        self.val_scores = []\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "        print('Train started at', start_time)\n",
    "        for epoch in tqdm(range(1, epochs + 1)):\n",
    "            # Training\n",
    "            score_epoch = []\n",
    "            for batch_i, (imgs_source, imgs_target) in tqdm(enumerate(self.data_loader.load_batch(batch_size))):\n",
    "                imgs_fake = self.generator.predict(imgs_source)\n",
    "                d_score_real_batch = self.discriminator.train_on_batch([imgs_target, imgs_source], valid)\n",
    "                d_score_fake_batch = self.discriminator.train_on_batch([imgs_fake,   imgs_source], fake)\n",
    "                g_score_batch = self.combined.train_on_batch(imgs_source, [valid, imgs_target])\n",
    "                score_epoch.append((*d_score_real_batch, *d_score_fake_batch, *g_score_batch))\n",
    "            score = tuple(np.mean(score_epoch, axis=0))\n",
    "            self.scores.append(score)\n",
    "\n",
    "            # Validating\n",
    "            val_scores_epoch = []\n",
    "            for batch_i, (imgs_source, imgs_target) in tqdm(enumerate(self.data_loader.load_batch(batch_size, is_testing=True))):\n",
    "                imgs_fake = self.generator.predict(imgs_source)\n",
    "                d_val_score_real_batch = self.discriminator.test_on_batch([imgs_target, imgs_source], valid)\n",
    "                d_val_score_fake_batch = self.discriminator.test_on_batch([imgs_fake,   imgs_source], fake)\n",
    "                g_val_score_batch = self.combined.train_on_batch(imgs_source, [valid, imgs_target])\n",
    "                val_scores_epoch.append((*d_val_score_real_batch, *d_val_score_fake_batch, *g_val_score_batch))\n",
    "            val_score = tuple(np.mean(val_scores_epoch, axis=0))\n",
    "            self.val_scores.append(val_score)\n",
    "                \n",
    "            elapsed_time = datetime.datetime.now() - start_time\n",
    "            print(\"[Epoch: %d/%d][D val_loss: %f, val_acc: %3d%%][G val_loss: %f][time: %s]\" % (\n",
    "                epoch, epochs, (val_score[0] + val_score[2])/2, 100*(val_score[1]+val_score[3]), val_score[4], elapsed_time)\n",
    "            )\n",
    "            self._sample_images(epoch)\n",
    "            self._save_model(epoch)\n",
    "\n",
    "    def _sample_images(self, epoch, samples=3):\n",
    "        os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n",
    "\n",
    "        imgs_source, imgs_target= self.data_loader.load_data(batch_size=samples, is_testing=True)\n",
    "        imgs_fake = self.generator.predict(imgs_source)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_source, imgs_fake, imgs_target])\n",
    "        gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "\n",
    "        titles = ['Source', 'Generated', 'Target']\n",
    "        r, c = 3, samples\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[c * i + j])\n",
    "                axs[i,j].set_title(titles[i])\n",
    "                axs[i,j].axis('off')\n",
    "        fig.savefig(\"images/%s/%d.png\" % (self.dataset_name, epoch))\n",
    "        plt.close()\n",
    "    \n",
    "    def _save_model(self, epoch):\n",
    "        if len(self.val_scores) < 2:\n",
    "            return\n",
    "        if min(row[4] for row in self.val_scores[:-1]) > self.val_scores[-1][4]:\n",
    "            # when g_val_loss is the smallest during a training\n",
    "            os.makedirs('saved_model', exist_ok=True)\n",
    "            self.generator.save('saved_model/model-{:03d}.h5'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pix2pix = Pix2Pix(dataset_name='sakura')\n",
    "pix2pix.generator.summary()\n",
    "pix2pix.discriminator.summary()\n",
    "pix2pix.combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix2pix.train(epochs=200, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot generator and discriminator accuracy and loss all\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "x = [i + 1 for i in range(pix2pix.epochs)]\n",
    "d_real_loss, d_real_acc, d_fake_loss, d_fake_acc, g_loss, _, _ = zip(*pix2pix.scores)\n",
    "\n",
    "plt.plot(x, d_real_loss, label=\"d_real_loss\")\n",
    "plt.plot(x, d_fake_loss, label=\"d_fake_loss\")\n",
    "plt.plot(x, g_loss,      label=\"g_loss\")\n",
    "plt.plot(x, d_real_acc,  label=\"d_real_acc\")\n",
    "plt.plot(x, d_fake_acc,  label=\"d_fake_acc\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('a.u.')\n",
    "plt.legend()\n",
    "plt.title('Training loss of pix2pix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_real_val_loss, d_real_val_acc, d_fake_val_loss, d_fake_val_acc, g_val_loss, _, _ = zip(*pix2pix.val_scores)\n",
    "\n",
    "plt.plot(x, d_real_val_loss, label=\"d_val_real_loss\")\n",
    "plt.plot(x, d_fake_val_loss, label=\"d_val_fake_loss\")\n",
    "plt.plot(x, g_val_loss,      label=\"g_val_loss\")\n",
    "plt.plot(x, d_real_val_acc,  label=\"d_val_real_acc\")\n",
    "plt.plot(x, d_fake_val_acc,  label=\"d_val_fake_acc\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('a.u.')\n",
    "plt.legend()\n",
    "plt.title('Validating loss of pix2pix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
